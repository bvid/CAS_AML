{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62645c0c-3f67-465d-abad-6e00e6ea683d",
   "metadata": {},
   "source": [
    "# Part II: Visualizations latent space with toolkit 'Kerac'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcd2c5-4e30-458d-b78d-53feb5b367ae",
   "metadata": {},
   "source": [
    "CAS AML Module3 by Beatriz Vidondo\n",
    "\n",
    "Using keract: https://github.com/philipperemy/keract\n",
    "Keract toolkit allows to “get the activations (outputs) and gradients for each layer of Keras models” (Rémy, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bf084-5fe6-4154-b2e4-642070f18df5",
   "metadata": {},
   "source": [
    "Code adapted from \n",
    "https://www.machinecurve.com/index.php/2019/12/26/how-to-visualize-the-encoded-state-of-an-autoencoder-with-keras/#visualizing-the-encoded-state-what-we-want-to-achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5400fa28-d2c6-4ed3-96c4-5b2e2da705f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keract import get_activations, display_activations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56653828-cbaa-4018-ad62-6212269327d0",
   "metadata": {},
   "source": [
    "This time I use a larger number of neurons in the latent space: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f0ee4f-c897-418b-830f-a3cb55e20b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "img_width, img_height = 28, 28\n",
    "initial_dimension = img_width * img_height\n",
    "batch_size = 24\n",
    "no_epochs = 10\n",
    "validation_split = 0.1\n",
    "verbosity = 1\n",
    "encoded_dim = 50 #number of nodes in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a66f763-04b1-4c1b-af68-e0c9e759031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 files belonging to 3 classes.\n",
      "Using 270 files for training.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Using 30 files for validation.\n"
     ]
    }
   ],
   "source": [
    "data_dir_str = 'C:/Users/beatriz/Documents/Python/MyModule3/data/squarecircletriang/shapes/'\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir_str,\n",
    "    #label_mode = None,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    color_mode='grayscale',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir_str,\n",
    "    #label_mode = None,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    color_mode='grayscale',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40078a44-26b6-44e4-b9e1-d08b99b13115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 28, 28, 1)\n",
      "(30, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# store and rescale the image data as well\n",
    "train_images4D=np.concatenate(list(map(lambda x: x[0].numpy()/255, train_ds)))\n",
    "test_images4D=np.concatenate(list(map(lambda x: x[0].numpy()/255, test_ds)))\n",
    "print(train_images4D.shape)\n",
    "print(test_images4D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404d4992-4f24-4932-accd-7438005b8572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 28, 28)\n",
      "(30, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# in case of color pics, select only the blue/last channel\n",
    "#train_images = train_images4D[:,:,:,2]\n",
    "#in case of grayscale pics, take the one color channel\n",
    "train_images = train_images4D[:,:,:,0]\n",
    "print(train_images.shape)\n",
    "#view the data of first picture\n",
    "#train3D[0]\n",
    "test_images = test_images4D[:,:,:,0]\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5130664f-bf10-4af0-aae3-3be47316baa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 784)\n",
      "(30, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape data\n",
    "input_train = train_images.reshape(train_images.shape[0], initial_dimension)\n",
    "input_test = test_images.reshape(test_images.shape[0], initial_dimension)\n",
    "input_shape = (initial_dimension, )\n",
    "print(input_train.shape); print(input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e089cbd-fd4b-4ba6-8122-5280d52ddfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45b04f-0a48-4d40-8b6d-b488555cd3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5d2d36-01e8-40e8-8c01-6735a03dbf9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Version 1: define model with Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "605603c0-3e5c-42cf-9b82-b9db4d231ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers\n",
    "inputs = Input(shape=input_shape)\n",
    "encoding_layer = Dense(encoded_dim, activation='relu', kernel_initializer='he_normal')(inputs)\n",
    "decoding_layer = Dense(initial_dimension, activation='sigmoid')(encoding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96788a9-13e2-45bd-8f0d-4a79264cfd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382626b6-ae96-493f-b366-cc32dc1113cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the autoencoder\n",
    "autoencoder = Model(inputs, decoding_layer, name='full_autoencoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36abda17-e8a0-41fc-87d0-5855329e4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoder\n",
    "encoder = Model(inputs, encoding_layer, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad6065-7f13-4d2a-be05-1fcf89a31c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8857ce-1eec-4aa9-b371-bc05ccea9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the decoder\n",
    "encoded_input = Input(shape=(encoded_dim, ))\n",
    "final_ae_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, final_ae_layer(encoded_input), name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83462aa6-7b71-4b25-b2fd-971a5b7857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder\n",
    "encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7f418c-67f6-4595-86c4-9bd3b3a2e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"full_autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 79,234\n",
      "Trainable params: 79,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "=================================================================\n",
      "Total params: 39,250\n",
      "Trainable params: 39,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 39,984\n",
      "Trainable params: 39,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Give us some insights\n",
    "autoencoder.summary()\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecea1469-e639-4313-b623-82389a61e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 4s - loss: 0.7029\n",
      "11/11 [==============================] - 1s 20ms/step - loss: 0.5850 - val_loss: 0.3844\n",
      "Epoch 2/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.3870\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2992 - val_loss: 0.2230\n",
      "Epoch 3/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2354\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2117 - val_loss: 0.1925\n",
      "Epoch 4/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2029\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1985 - val_loss: 0.1900\n",
      "Epoch 5/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1977\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1960 - val_loss: 0.1877\n",
      "Epoch 6/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2075\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1948 - val_loss: 0.1871\n",
      "Epoch 7/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1884\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1943 - val_loss: 0.1869\n",
      "Epoch 8/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2021\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1940 - val_loss: 0.1867\n",
      "Epoch 9/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1978\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1941 - val_loss: 0.1861\n",
      "Epoch 10/10\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2078\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.1860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c0c941310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit data\n",
    "autoencoder.fit(input_train, input_train, epochs=no_epochs, batch_size=batch_size, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e24090-b969-4403-9d77-9c7a569e076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Take a sample for visualization purposes\n",
    "# =============================================\n",
    "input_sample = input_test[:1]\n",
    "reconstruction = autoencoder.predict([input_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bf37f9-cee3-407c-bfb3-16ef32fa4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Visualize input-->reconstruction\n",
    "# =============================================\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(6, 3.5)\n",
    "input_sample_reshaped = input_sample.reshape((img_width, img_height))\n",
    "reconsstruction_reshaped = reconstruction.reshape((img_width, img_height))\n",
    "axes[0].imshow(input_sample_reshaped) \n",
    "axes[0].set_title('Original image')\n",
    "axes[1].imshow(reconsstruction_reshaped)\n",
    "axes[1].set_title('Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6899de70-8950-4d3c-ac09-b187aa6186a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 (1, 784) \n",
      "dense (1, 50) \n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Visualize encoded state with Keract\n",
    "# =============================================\n",
    "activations = get_activations(encoder, input_sample)\n",
    "display_activations(activations, cmap=\"gray\", save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5125ff-26eb-43ea-b9a1-1788d43e3f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423fc02-28a4-4b2f-a5f4-a075e60aa435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b86e05f7-7bff-443e-b9f9-c44a67ea032f",
   "metadata": {},
   "source": [
    "## Version 2: define model with Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8238fe2a-a37c-4aaa-930e-b2c4edbe93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keract import get_activations, display_activations\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "128c5e37-3740-40d3-90c6-f254982cb2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "img_width, img_height = 28, 28\n",
    "initial_dimension = img_width * img_height\n",
    "batch_size = 24\n",
    "no_epochs = 100\n",
    "validation_split = 0.1\n",
    "verbosity = 1\n",
    "encoded_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331ecf7-0723-4727-89f8-95bd66f8970e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e4f938-3bdb-4732-95e4-7a1fda9ff9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 'autoencoder' full model\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(encoded_dim, activation='relu', kernel_initializer='he_normal', input_shape=input_shape))\n",
    "autoencoder.add(Dense(initial_dimension, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e7cd97-9c77-491b-931a-88fd9bdded5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               39984     \n",
      "=================================================================\n",
      "Total params: 79,234\n",
      "Trainable params: 79,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 3s - loss: 0.7040\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 0.6363 - val_loss: 0.4912\n",
      "Epoch 2/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.4970\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3852 - val_loss: 0.2681\n",
      "Epoch 3/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2769\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2398 - val_loss: 0.2042\n",
      "Epoch 4/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2191\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2034 - val_loss: 0.1916\n",
      "Epoch 5/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2019\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1971 - val_loss: 0.1884\n",
      "Epoch 6/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1967\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1952 - val_loss: 0.1873\n",
      "Epoch 7/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1888\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1946 - val_loss: 0.1866\n",
      "Epoch 8/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1891\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1942 - val_loss: 0.1872\n",
      "Epoch 9/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1829\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1942 - val_loss: 0.1875\n",
      "Epoch 10/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1904\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1941 - val_loss: 0.1868\n",
      "Epoch 11/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1824\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1940 - val_loss: 0.1867\n",
      "Epoch 12/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1850\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1940 - val_loss: 0.1872\n",
      "Epoch 13/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1858\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1938 - val_loss: 0.1861\n",
      "Epoch 14/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1915\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1937 - val_loss: 0.1861\n",
      "Epoch 15/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1939\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1936 - val_loss: 0.1864\n",
      "Epoch 16/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1911\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1937 - val_loss: 0.1866\n",
      "Epoch 17/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1844\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1937 - val_loss: 0.1865\n",
      "Epoch 18/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1943\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1937 - val_loss: 0.1866\n",
      "Epoch 19/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1968\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1936 - val_loss: 0.1861\n",
      "Epoch 20/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1961\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1936 - val_loss: 0.1861\n",
      "Epoch 21/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1853\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1936 - val_loss: 0.1866\n",
      "Epoch 22/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1955\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1936 - val_loss: 0.1865\n",
      "Epoch 23/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1783\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1935 - val_loss: 0.1862\n",
      "Epoch 24/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1949\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1935 - val_loss: 0.1856\n",
      "Epoch 25/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1954\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1935 - val_loss: 0.1856\n",
      "Epoch 26/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1970\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1934 - val_loss: 0.1861\n",
      "Epoch 27/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2026\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1933 - val_loss: 0.1859\n",
      "Epoch 28/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1938\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1932 - val_loss: 0.1860\n",
      "Epoch 29/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1806\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1933 - val_loss: 0.1866\n",
      "Epoch 30/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1913\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1933 - val_loss: 0.1864\n",
      "Epoch 31/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1971\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1933 - val_loss: 0.1859\n",
      "Epoch 32/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1804\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1932 - val_loss: 0.1860\n",
      "Epoch 33/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1904\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1931 - val_loss: 0.1856\n",
      "Epoch 34/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1880\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1931 - val_loss: 0.1864\n",
      "Epoch 35/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1870\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1929 - val_loss: 0.1857\n",
      "Epoch 36/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1791\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1930 - val_loss: 0.1851\n",
      "Epoch 37/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1865\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1929 - val_loss: 0.1855\n",
      "Epoch 38/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1956\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1928 - val_loss: 0.1859\n",
      "Epoch 39/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1694\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.1855\n",
      "Epoch 40/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1997\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1927 - val_loss: 0.1858\n",
      "Epoch 41/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1963\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1928 - val_loss: 0.1858\n",
      "Epoch 42/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1860\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1928 - val_loss: 0.1848\n",
      "Epoch 43/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1983\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1925 - val_loss: 0.1850\n",
      "Epoch 44/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1901\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1923 - val_loss: 0.1852\n",
      "Epoch 45/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1836\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1924 - val_loss: 0.1858\n",
      "Epoch 46/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1874\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1924 - val_loss: 0.1856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1824\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1924 - val_loss: 0.1851\n",
      "Epoch 48/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2037\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1922 - val_loss: 0.1849\n",
      "Epoch 49/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1866\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1922 - val_loss: 0.1848\n",
      "Epoch 50/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1953\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1923 - val_loss: 0.1853\n",
      "Epoch 51/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1866\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1919 - val_loss: 0.1856\n",
      "Epoch 52/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1906\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1917 - val_loss: 0.1846\n",
      "Epoch 53/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1913\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1917 - val_loss: 0.1845\n",
      "Epoch 54/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1968\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1916 - val_loss: 0.1843\n",
      "Epoch 55/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1999\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1916 - val_loss: 0.1842\n",
      "Epoch 56/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1863\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1914 - val_loss: 0.1842\n",
      "Epoch 57/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1867\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1914 - val_loss: 0.1843\n",
      "Epoch 58/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1856\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1912 - val_loss: 0.1839\n",
      "Epoch 59/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1906\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1910 - val_loss: 0.1838\n",
      "Epoch 60/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1971\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1909 - val_loss: 0.1836\n",
      "Epoch 61/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1858\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1906 - val_loss: 0.1840\n",
      "Epoch 62/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1898\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1905 - val_loss: 0.1837\n",
      "Epoch 63/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2016\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1906 - val_loss: 0.1835\n",
      "Epoch 64/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1952\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1904 - val_loss: 0.1837\n",
      "Epoch 65/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1830\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1902 - val_loss: 0.1836\n",
      "Epoch 66/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1895\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1900 - val_loss: 0.1832\n",
      "Epoch 67/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1734\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1897 - val_loss: 0.1827\n",
      "Epoch 68/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1763\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1897 - val_loss: 0.1832\n",
      "Epoch 69/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1886\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1894 - val_loss: 0.1825\n",
      "Epoch 70/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1844\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1893 - val_loss: 0.1822\n",
      "Epoch 71/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1819\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1890 - val_loss: 0.1821\n",
      "Epoch 72/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1902\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1887 - val_loss: 0.1822\n",
      "Epoch 73/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1816\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1886 - val_loss: 0.1822\n",
      "Epoch 74/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.2090\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.1816\n",
      "Epoch 75/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1796\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1879 - val_loss: 0.1813\n",
      "Epoch 76/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1955\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1875 - val_loss: 0.1807\n",
      "Epoch 77/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1764\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1874 - val_loss: 0.1811\n",
      "Epoch 78/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1996\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1871 - val_loss: 0.1807\n",
      "Epoch 79/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1890\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1867 - val_loss: 0.1800\n",
      "Epoch 80/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1925\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1862 - val_loss: 0.1798\n",
      "Epoch 81/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1710\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1862 - val_loss: 0.1802\n",
      "Epoch 82/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1819\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1861 - val_loss: 0.1799\n",
      "Epoch 83/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1946\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1853 - val_loss: 0.1790\n",
      "Epoch 84/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1849\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1849 - val_loss: 0.1787\n",
      "Epoch 85/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1958\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1846 - val_loss: 0.1783\n",
      "Epoch 86/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1771\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1843 - val_loss: 0.1787\n",
      "Epoch 87/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1811\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1842 - val_loss: 0.1780\n",
      "Epoch 88/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1795\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1834 - val_loss: 0.1778\n",
      "Epoch 89/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1878\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1830 - val_loss: 0.1775\n",
      "Epoch 90/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1971\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1766\n",
      "Epoch 91/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1818\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1824 - val_loss: 0.1770\n",
      "Epoch 92/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1836\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1820 - val_loss: 0.1764\n",
      "Epoch 93/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1825\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1813 - val_loss: 0.1760\n",
      "Epoch 94/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1938\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1809 - val_loss: 0.1755\n",
      "Epoch 95/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1753\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1809 - val_loss: 0.1753\n",
      "Epoch 96/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1802 - val_loss: 0.1749\n",
      "Epoch 97/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1892\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1800 - val_loss: 0.1751\n",
      "Epoch 98/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1741\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1794 - val_loss: 0.1737\n",
      "Epoch 99/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1726\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1791 - val_loss: 0.1748\n",
      "Epoch 100/100\n",
      "\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.1838\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1787 - val_loss: 0.1729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c0ee3e3a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Give us some insights\n",
    "autoencoder.summary()\n",
    "\n",
    "# Fit data\n",
    "autoencoder.fit(input_train, input_train, epochs=no_epochs, batch_size=batch_size, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c66225b0-0786-40f1-bb6c-de4acd128632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Take a sample for visualization purposes\n",
    "# =============================================\n",
    "input_sample = input_test[:1]\n",
    "reconstruction = autoencoder.predict([input_sample])\n",
    "\n",
    "# =============================================\n",
    "# Visualize input-->reconstruction\n",
    "# =============================================\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(6, 3.5)\n",
    "input_sample_reshaped = input_sample.reshape((img_width, img_height))\n",
    "reconsstruction_reshaped = reconstruction.reshape((img_width, img_height))\n",
    "axes[0].imshow(input_sample_reshaped) \n",
    "axes[0].set_title('Original image')\n",
    "axes[1].imshow(reconsstruction_reshaped)\n",
    "axes[1].set_title('Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34ab1be-dc9b-49e5-9d7f-36c5e928934f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_2_input (1, 784) \n",
      "dense_2 (1, 50) \n",
      "dense_3 (1, 784) \n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Visualize encoded state with Keract\n",
    "# =============================================\n",
    "activations = get_activations(autoencoder, input_sample)\n",
    "display_activations(activations, cmap=\"gray\", save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0785bc-d2b3-4f28-b335-6caedae6f29a",
   "metadata": {},
   "source": [
    "We get an extra visualization: the output by the decoder before it’s reshaped into 28 x 28 pixels format,\n",
    "but this is due to the relative inflexibility of the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a65a1-4280-4a47-bd0d-aba089472412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66274177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f7b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a43a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c4ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
